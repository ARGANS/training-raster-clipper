{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from affine import Affine\n",
    "from geopandas.geodataframe import GeoDataFrame\n",
    "from rasterio.features import rasterize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from training_raster_clipper.core.logging import log_info\n",
    "from training_raster_clipper.core.models import TrainingConfiguration, TrainingFunctions\n",
    "from training_raster_clipper.core.visualization import (\n",
    "    plot_array,\n",
    "    plot_geodataframe,\n",
    "    plot_rgb_data_array,\n",
    ")\n",
    "from training_raster_clipper.custom_types import (\n",
    "    BandNameType,\n",
    "    ClassificationResult,\n",
    "    ClassifiedSamples,\n",
    "    FeatureClassNameToId,\n",
    "    PolygonMask,\n",
    "    ResolutionType,\n",
    ")\n",
    "\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://stackoverflow.com/questions/18786912/get-output-from-the-logging-module-in-ipython-notebook\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.info(\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user = \"eschalk\"\n",
    "# user = \"eschalk_debug\"\n",
    "user = \"emunaibari\"\n",
    "\n",
    "if user == \"emunaibari\":\n",
    "    raster_input_path = Path(\n",
    "        \"D:/Trainings/HW/Data/\"\n",
    "    )\n",
    "    polygons_input_path = Path(\n",
    "        \"D:/Trainings/HW/Ploygon/Polygons.geojson\"\n",
    "    )\n",
    "    output_path = Path('D:/Trainings/HW/generated/')\n",
    "elif user == \"eschalk\":\n",
    "    raster_input_path = Path(\n",
    "        r\"..\\resources\\solution\\example_sentinel_files\\SENTINEL.SAFE\\GRANULE\\L2A_T31TCJ_A038658_20221116T105603\\IMG_DATA\\R60m\"    )\n",
    "    polygons_input_path = Path(\n",
    "        r\"D:\\Profils\\eschalk\\dev\\playground\\python\\training\\training-raster-clipper\\resources\\your_work\\Polygons_emunaibari.geojson\"\n",
    "    )\n",
    "    output_path = Path('../generated/emunaibari')\n",
    "elif user == \"eschalk_debug\":\n",
    "    raster_input_path = Path(\n",
    "        r\"..\\resources\\solution\\example_sentinel_files\\SENTINEL.SAFE\\GRANULE\\L2A_T31TCJ_A038658_20221116T105603\\IMG_DATA\\R60m\"    )\n",
    "    polygons_input_path=(\n",
    "        Path(\".\").resolve().parent / Path(\"resources/solution/polygons.geojson\")\n",
    "    )\n",
    "    output_path = Path('../generated/emunaibari')\n",
    "    \n",
    "else: \n",
    "    raster_input_path = None\n",
    "    polygons_input_path = None\n",
    "    output_path = None\n",
    "\n",
    "assert raster_input_path.exists() and raster_input_path.is_dir()\n",
    "assert polygons_input_path.exists() and polygons_input_path.is_file()\n",
    "\n",
    "if not (output_path.exists() and output_path.is_dir()):\n",
    "    output_path.mkdir()\n",
    "\n",
    "config = TrainingConfiguration(\n",
    "    verbose=True,\n",
    "    show_plots=True,\n",
    "    resolution=60,\n",
    "    band_names=(\"B04\", \"B03\", \"B02\", \"B8A\"),\n",
    "    raster_input_path=raster_input_path,\n",
    "    polygons_input_path=polygons_input_path,\n",
    "    csv_output_path = (output_path.resolve() / Path(\"classified_points.csv\")),\n",
    "    raster_output_path=(output_path.resolve() / Path(\"sklearn_raster.tiff\")),\n",
    "    implementation_name=\"eschalk\",\n",
    ")\n",
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = config.verbose\n",
    "show_plots = config.show_plots\n",
    "\n",
    "resolution = config.resolution\n",
    "band_names = config.band_names\n",
    "\n",
    "raster_input_path = config.raster_input_path\n",
    "polygons_input_path = config.polygons_input_path\n",
    "csv_output_path = config.csv_output_path\n",
    "raster_output_path = config.raster_output_path\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Load a GeoJSON file with `geopandas`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feature_polygons(input_path: Path) -> GeoDataFrame:\n",
    "    # Loading the Polygons\n",
    "    poly_file = gpd.read_file(input_path)\n",
    "    # Converting the coordinate system from EPSG 4326 format, to the Sentinel-2 raster: 32631\n",
    "    poly_file = poly_file.to_crs(32631)\n",
    "\n",
    "    return poly_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons = load_feature_polygons(polygons_input_path)\n",
    "if verbose:\n",
    "    log_info(polygons, \"polygons\")\n",
    "if show_plots:\n",
    "    plot_geodataframe(polygons, f\"{load_feature_polygons.__name__}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Load a Sentinel-2 raster with `rioxarray`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentinel_data(\n",
    "    sentinel_product_location: Path,\n",
    "    resolution: ResolutionType,\n",
    "    band_names: tuple[BandNameType, ...],\n",
    ") -> xr.DataArray:\n",
    "    \"\"\"Loads sentinel product\n",
    "\n",
    "    Example input path: `S2A_MSIL2A_20221116T105321_N0400_R051_T31TCJ_20221116T170958.SAFE`\n",
    "\n",
    "    Args:\n",
    "        sentinel_product_location (Path): Location of the .SAFE folder containing a Sentinel-2 product.\n",
    "\n",
    "    Returns:\n",
    "        xr.DataArray: A DataArray containing the 3 RGB bands from the visible spectrum\n",
    "    \"\"\"\n",
    "\n",
    "    # Reading each band into an xarray DataArray and store in a dictionary, using dictionary comprehension\n",
    "    band_data = {\n",
    "        band: rxr.open_rasterio(\n",
    "            next(sentinel_product_location.glob(f\"*{band}*\")), masked=True\n",
    "        ).squeeze()\n",
    "        for band in band_names\n",
    "    }\n",
    "\n",
    "    # The .squeeze() is used to remove dimensions of size 1 from an xarray DataArray or Dataset.\n",
    "    # When you read a single-band raster file using rioxarray or rasterio, it usually comes in with dimensions like (1, height, width).\n",
    "    # The masked=True argument is used when opening the raster file with rioxarray to automatically convert any NoData values in the raster to NaN (Not a Number) in the resulting xarray DataArray.\n",
    "    # rioxarray and rasterio can automatically detect NoData values based on the raster file's metadata.\n",
    "\n",
    "    # Concatenating the individual bands into a single xarray DataArray along a new 'band' dimension\n",
    "    all_bands = xr.concat(list(band_data.values()), dim=\"band\")\n",
    "    all_bands[\"band\"] = list(\n",
    "        band_data.keys()\n",
    "    )  # Assigning band names to the 'band' coordinate\n",
    "\n",
    "    # Converting the data type to np.float32\n",
    "    all_bands = all_bands.astype(np.float32)\n",
    "\n",
    "    # Pre-processing on rasters\n",
    "    offset = -1000.0\n",
    "    quantification = 10000.0\n",
    "    # Normalization\n",
    "    all_bands = (all_bands + offset) / quantification\n",
    "\n",
    "    return all_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters = load_sentinel_data(raster_input_path, resolution, band_names)\n",
    "if verbose:\n",
    "    log_info(rasters, \"rasters\")\n",
    "if show_plots:\n",
    "    plot_rgb_data_array(rasters, f\"{load_sentinel_data.__name__}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Rasterize the polygons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasterize_geojson(\n",
    "    data_array: xr.DataArray,\n",
    "    training_classes: GeoDataFrame,\n",
    ") -> tuple[PolygonMask, FeatureClassNameToId]:\n",
    "    \"\"\"Burns a set of vectorial polygons to a raster.\n",
    "\n",
    "    See https://gis.stackexchange.com/questions/316626/rasterio-features-rasterize\n",
    "\n",
    "    Args:\n",
    "        data_array (xr.DataArray): The Sentinel raster, from which data is taken, such as the transform or the shape.\n",
    "        training_classes (GeoDataFrame): The input set of classified multipolygons to burn\n",
    "\n",
    "    Returns:\n",
    "        xr.DataArray: A mask raster generated from the polygons, representing the same geographical region as the source dataarray param\n",
    "                      0 where no polygon were found, and integers representing classes in order of occurence in the GeoDataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # extracting the shape from the raster\n",
    "    raster_shape = data_array.isel(band=0).shape\n",
    "\n",
    "    # the transform\n",
    "    transform = rasters.spatial_ref.GeoTransform\n",
    "    # the output shows a string displaying a GDAL-style geotransform parameters (six parameters):\n",
    "    # -a: top left x coordinate (longitude)\n",
    "    # -b: width of a pixel in x direction\n",
    "    # -c: rotation (typically 0)\n",
    "    # -d: top left y coordinate (latitude)\n",
    "    # -e: rotation (typically 0)\n",
    "    # -f: height of a pixel (in y direction, usually negative)\n",
    "\n",
    "    # Getting the different paramaters and convert them to floats instead of strings\n",
    "    transform = [float(a) for a in transform.split()]\n",
    "\n",
    "    # Converting the transform to the required format (Affine) by feature.rasterize\n",
    "    transform = Affine.from_gdal(*transform)\n",
    "\n",
    "    # Getting the Polygons geometry\n",
    "    # geom = [\n",
    "    #     (g, v)\n",
    "    #     for g, v in zip(training_classes.geometry, training_classes.id.values + 1)\n",
    "    # ]\n",
    "    geom = [(g, v) for g, v in zip(training_classes.geometry, training_classes.index + 1)]\n",
    "\n",
    "    # Getting the classes\n",
    "    # unique_classes = dict(\n",
    "    #     zip(training_classes[\"class\"].values, training_classes.id.values + 1)\n",
    "    # )\n",
    "    unique_classes = dict(zip(training_classes[\"class\"].values, training_classes.index + 1))\n",
    "    cls = {cl: val for cl, val in unique_classes.items()}\n",
    "\n",
    "    # Mask building: resizing and geomtery encoding. Ensuring the mask will have the correct designated type (PolygonMask)\n",
    "    mask: PolygonMask = rasterize(\n",
    "        geom,\n",
    "        out_shape=raster_shape,\n",
    "        transform=transform,\n",
    "        all_touched=False,\n",
    "        dtype=np.uint8,\n",
    "    )\n",
    "\n",
    "    return [mask, cls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnt_polygons, mapping = rasterize_geojson(rasters, polygons)\n",
    "if verbose:\n",
    "    log_info(burnt_polygons, \"burnt_polygons\")\n",
    "    log_info(mapping, \"mapping\")\n",
    "if show_plots:\n",
    "    plot_array(burnt_polygons, f\"{rasterize_geojson.__name__}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Intersect the Sentinel-2 raster with polygons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_clips(\n",
    "    data_array: xr.DataArray, burnt_polygons: PolygonMask, mapping: FeatureClassNameToId\n",
    ") -> ClassifiedSamples:\n",
    "    \"\"\"Extract RGB values covered by classified polygons\n",
    "\n",
    "    Args:\n",
    "        data_array (xr.DataArray): RGB raster\n",
    "        burnt_polygons (PolygonMask): Rasterized classified multipolygons\n",
    "\n",
    "    Returns:\n",
    "        _type_: A list of the RGB values contained in the data_array and their corresponding classes\n",
    "    \"\"\"\n",
    "    # To host a new xarray.Dataset containing the reflectance and the features ID\n",
    "    ref_feature = None\n",
    "    # Getting the features IDs from the mapping dictionary\n",
    "    for _, id_feature in mapping.items():\n",
    "        # Flattening the rasters reflectance and assign it to new dimension variable z\n",
    "        # ref = data_array.stack(z=(\"x\", \"y\"))\n",
    "        ref = data_array.stack(z=(\"y\", \"x\"))\n",
    "        # Flattening the mask\n",
    "        poly = burnt_polygons.flatten()\n",
    "        # Using the mask to select the reflectance pixels under the current feature in the loop (water, forest, or farmland)\n",
    "        ref = ref.isel(z=poly == id_feature)\n",
    "        # Removing un-needed variables\n",
    "        ref = ref.drop_vars((\"y\", \"x\", \"spatial_ref\"))\n",
    "\n",
    "        # Putting the id feature into an xr.Dataset similar the selected reflectance\n",
    "        feature_arr = xr.ones_like(ref.z) * id_feature\n",
    "\n",
    "        # Combining the reflectance data, if the xr.Dataset exist or generating a one if not\n",
    "        if ref_feature:\n",
    "            ref_feature = xr.concat(\n",
    "                [\n",
    "                    ref_feature,\n",
    "                    xr.Dataset({\"reflectance\": ref, \"feature_id\": feature_arr}),\n",
    "                ],\n",
    "                dim=\"z\",\n",
    "            )\n",
    "        else:\n",
    "            ref_feature = xr.Dataset({\"reflectance\": ref, \"feature_id\": feature_arr})\n",
    "\n",
    "    return ref_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_rgb_rows = produce_clips(rasters, burnt_polygons, mapping)\n",
    "if verbose:\n",
    "    log_info(classified_rgb_rows, \"classified_rgb_rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_rgb_rows.reflectance.sel(band=\"B04\").plot()\n",
    "classified_rgb_rows.reflectance.sel(band=\"B03\").plot()\n",
    "classified_rgb_rows.reflectance.sel(band=\"B02\").plot()\n",
    "classified_rgb_rows.reflectance.sel(band=\"B8A\").plot()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Persist the intersection to a CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_to_csv(\n",
    "    classified_rgb_rows: ClassifiedSamples,\n",
    "    csv_output_path: Path,\n",
    ") -> None:\n",
    "    # Converting the reflectance DataArray into pandas.DataFrame after transposing the DataArray so we have four columns corresponding to the four bands\n",
    "    pd_df = classified_rgb_rows.reflectance.T.to_pandas()\n",
    "    # Adding the features IDs to the DataFrame\n",
    "    pd_df[\"feature_id\"] = classified_rgb_rows.feature_id.data\n",
    "\n",
    "    # Saveing the DataFrame as CSV file with separator ';'\n",
    "    pd_df.to_csv(csv_output_path, sep=\";\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_to_csv(classified_rgb_rows, csv_output_path)\n",
    "log_info(f\"Written CSV output {csv_output_path}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Train a machine learning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentinel_data(\n",
    "    rasters: xr.DataArray, classified_rgb_rows: ClassifiedSamples\n",
    ") -> ClassificationResult:\n",
    "    # Getting the features reflectance and the labels, the current shape of the reflectance array is 4xn (row: bands, col: ref), so we transpose it to get nx4 (row: ref, col: bands)\n",
    "    feature_ref = classified_rgb_rows.reflectance.T\n",
    "    feature_label = classified_rgb_rows.feature_id\n",
    "\n",
    "    # Initiating the classifier, n_job is to speed the process through parallelization\n",
    "    classifier = RandomForestClassifier(n_jobs=4)  # n_estimators=100, random_state=42)\n",
    "\n",
    "    # Training the model in the features reflectance and the labels\n",
    "    classifier.fit(feature_ref, feature_label)\n",
    "\n",
    "    # Preparing the rasters for prediction by flattening the reflectance data assign it to new dimension variable z and transpose it to match the train data\n",
    "    flt_data = rasters.stack(z=(\"y\", \"x\")).T\n",
    "    # flt_data = rasters.stack(z=(\"x\", \"y\")).T\n",
    "\n",
    "    # Predicting the classes of the rasters\n",
    "    prd_classes = classifier.predict(flt_data)\n",
    "\n",
    "    # Reshaping the prediction result to match the original shape and put it into [through .copy(data=)] xr.DataArry with the same metadata and attribute as the rasters\n",
    "    xr_holder = rasters.isel(band=0, drop=True)\n",
    "    xr_holder = xr_holder.transpose(\"x\", \"y\") # debug \n",
    "    classifier_output = xr_holder.copy(data=prd_classes.reshape(xr_holder.shape))\n",
    "    # Ensuring the same data type as the original raster\n",
    "    classifier_output = classifier_output.astype(np.float32)\n",
    "\n",
    "    return classifier_output\n",
    "\n",
    "\n",
    "# A function to read the classification CSV file provided in the solution to test the model and check the impact of the Polygons mask\n",
    "# used to extract the classes reflectance\n",
    "def classify_sentinel_data_sol(\n",
    "    rasters: xr.DataArray, classified_rgb_rows_sol: Path\n",
    ") -> ClassificationResult:\n",
    "    # Loading the classified rgb reflectenace\n",
    "    df_classified_ref = pd.read_csv(classified_rgb_rows_sol, sep=\";\")\n",
    "\n",
    "    # Getting the features reflectance and the labels\n",
    "    feature_ref = df_classified_ref[[\"B04\", \"B03\", \"B02\", \"B8A\"]].values\n",
    "    # feature_ref = df_classified_ref[[\"B04\", \"B8A\"]].values\n",
    "    feature_label = df_classified_ref.feature_id.values\n",
    "\n",
    "    # Initiating the classifier, n_job is to speed the process through parallelization\n",
    "    classifier = RandomForestClassifier(n_jobs=4)  # n_estimators=100, random_state=42)\n",
    "\n",
    "    # Training the model in the features reflectance and the labels\n",
    "    classifier.fit(feature_ref, feature_label)\n",
    "\n",
    "    # Preparing the rasters for prediction by flattening the reflectance data assign it to new dimension variable z and transpose it to match the train data\n",
    "    flt_data = rasters.stack(z=(\"x\", \"y\")).T\n",
    "    # flt_data = np.reshape(rasters.isel(band=[0,3]).stack(z=(\"x\", \"y\")).T.data, (-1,feature_ref.shape[1]))\n",
    "\n",
    "    # Predicting the classes of the rasters\n",
    "    prd_classes = classifier.predict(flt_data)\n",
    "\n",
    "    # Reshaping the prediction result to match the original shape and put it into [through .copy(data=)] xr.DataArry with the same metadata and attribute as the rasters\n",
    "    xr_holder = rasters.isel(band=0, drop=True)\n",
    "    classifier_output = xr_holder.copy(data=prd_classes.reshape(xr_holder.shape).T)\n",
    "    # Ensuring the same data type as the original raster\n",
    "    classifier_output = classifier_output.astype(np.float32)\n",
    "\n",
    "    return classifier_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_result = classify_sentinel_data(rasters, classified_rgb_rows)\n",
    "\n",
    "# classify_sentinel_data_sol_path = Path(\n",
    "#     \"D:/Trainings/HW/generated/classified_points_sol_to_read.csv\"\n",
    "# )\n",
    "# classification_result = classify_sentinel_data_sol(\n",
    "#     rasters, classify_sentinel_data_sol_path\n",
    "# )\n",
    "\n",
    "if verbose:\n",
    "    log_info(classification_result, \"classification_result\")\n",
    "if show_plots:\n",
    "    plot_array(classification_result, f\"{classify_sentinel_data.__name__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7) Export the classification raster result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_classification_to_raster(\n",
    "    raster_output_path: Path, classification_result: ClassificationResult\n",
    ") -> None:\n",
    "    # Retrieving the crs_wkt attribute from the spatial_ref dimension (probably unnecessary step as the classification_result is a xr.DataArry with the same metadata and attributes as the raster)\n",
    "    crs_wkt = classification_result.spatial_ref.crs_wkt\n",
    "    # Setting the CRS based on the crs_wkt attribute of the spatial_ref dim of the original sentinel raster\n",
    "    classification_result.rio.write_crs(crs_wkt, inplace=True)\n",
    "    # Storing the resulted raster of the classification\n",
    "    classification_result.rio.to_raster(raster_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_classification_to_raster(raster_output_path, classification_result)\n",
    "log_info(f\"Written Classified Raster to {raster_output_path}\")\n",
    "\n",
    "# --\n",
    "\n",
    "log_info(\"Congratulations, you reached the end of the tutorial!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ker1",
   "language": "python",
   "name": "ker1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
